ğŸ“Œ MLOps Mini Project â€“ SageMaker Pipelines + GitHub Actions

This repo contains a sample ML pipeline using Amazon SageMaker Pipelines for training & evaluation, triggered via GitHub Actions CI/CD.

ğŸš€ How it works

Developer pushes code â†’ GitHub Actions runs:

Format check (Black)

Lint (Ruff)

Type check (Mypy)

Unit tests (Pytest)

If CI passes â†’ SageMaker Pipeline is automatically upserted & executed.

Pipeline steps:

TrainModel â†’ trains with src/train.py

EvaluateModel â†’ evaluates with src/evaluate.py and stores metrics.json in S3

ğŸ‘©â€ğŸ’» Developer Setup
python -m pip install -r requirements.txt
python -m pip install pre-commit
python -m pre_commit install


Workflow:

git add .
git commit -m "msg"   # pre-commit auto-formats & lints
git commit -m "msg"   # commit again if first try modified files
git push              # CI + SageMaker pipeline run

ğŸ§ª Run tests locally
python -m pytest -q

â–¶ï¸ Manually run SageMaker pipeline (optional)
python -m pipelines.run_pipeline \
  --region <region> \
  --role-arn <role> \
  --default-bucket <s3-bucket> \
  --input-data-uri <s3-input-csv>

Run locally

Recommended setup
Create a venv and install minimal deps

python -m venv .venv
source .venv/bin/activate   # use .venv\Scripts\activate on Windows
python -m pip install --upgrade pip
python -m pip install pandas scikit-learn joblib
# Optionally run full requirements if you want CI/tools: pip install -r requirements.txt

Train locally
python -m src.train --train-data data/housing.csv --model-dir model

Evaluate locally
python -m src.evaluate --model-dir model --test-data data/housing.csv --output-dir eval

ğŸ” Required GitHub Secrets
Secret	Purpose
AWS_ACCESS_KEY_ID	AWS access key
AWS_SECRET_ACCESS_KEY	AWS secret
SAGEMAKER_ROLE_ARN	SageMaker execution role

â­ Notes

Always commit formatted code (pre-commit takes care of this).

CI must be green for SageMaker pipeline to run.

Shut down SageMaker Studio apps when not in use to avoid cost.